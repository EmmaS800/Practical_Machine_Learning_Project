---
title: "Practical_Machine_Learning_Project"
author: "Emma Schelhase"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

The goal of this project is to predict the manner in which 6 participants performed barbell lifts.  
This is defined by the **classe** variable in the training set.  
Data is gathered from accelerometers on the belt, forearm, arm, and dumbbell.  
A machine learning model was built, cross-validated, the out-of-sample error was estimated, 20 distinct test cases were be predicted.

## 1. Data Processing

Loading the required libraries and download the training and testing datasets.

```{r data_processing, echo=TRUE}
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)

trainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))

dim(training)
dim(testing)
```

### 1.1 Data Cleaning

The dataset contains many columns with missing values (NA) and metadata (timestamps, user names) that are not relevant for predicting physical movement.  
Therefore, the following aspects of the data can be removed:

- Remove columns with high NA content
- Remove metadata: The first 7 columns (ID, user_name, timestamps, windows) are removed to prevent the model from overfitting to specific time windows or subjects.

```{r data_cleaning, echo=TRUE}
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]

training <- training[, -c(1:7)]
testing <- testing[, -c(1:7)]

dim(training)
```

### 1.2 Data Partitioning
The cleaned training data is split into a Training Set (70%) for building the model and a Validation Set (30%) for cross-validation and out-of-sample error estimation.

```{r data_partitioning, echo=TRUE}
set.seed(12345)
inTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
myTraining <- training[inTrain, ]
myValidation <- training[-inTrain, ]
```

## 2. Model Building
The Random Forest algorithm will be used because it is widely known for high accuracy in classification tasks and handles non-linear variables well.

### 2.1 Cross-Validation Strategy
K-fold cross-validation is used in this model.  
In this configuration, 3 folds were used in an effort to balance accuracy with computational efficiency.

```{r cross_validation, echo=TRUE, cache=TRUE}

control <- trainControl(method="cv", number=3, verboseIter=FALSE)

# Training the Random Forest model
modFitRF <- train(classe ~ ., data=myTraining, method="rf", trControl=control)

modFitRF$finalModel
```

## 3. Model Evaluation
### 3.1 Expected Out-of-Sample Error

Applying the model to the "myValidation" set (which the model has not seen) to estimate the out-of-sample error

```{r model_eval, echo=TRUE, cache=TRUE}

# Predict on the validation set
predRF <- predict(modFitRF, myValidation)

# Confusion Matrix to see accuracy
confMat <- confusionMatrix(predRF, as.factor(myValidation$classe))
confMat

# Extract Accuracy and Out-of-Sample Error
accuracy <- confMat$overall['Accuracy']
ose <- 1 - accuracy

cat("Model Accuracy:", accuracy, "\n")
cat("Estimated Out-of-Sample Error:", ose, "\n")
```

The confusion matrix shows the accuracy of the model on the validation data.  
The Out-of-Sample Error is calculated as $1 - Accuracy$.  
Given the typically high performance of Random Forests on this dataset, we expect an accuracy above 99%.

## 4. Prediction on Test Cases
Finally, the trained model will be applied to the original 20 test cases provided in the testing CSV.
*These predictions will be submitted to the Course Project Prediction Quiz.

```{r test_prediction, echo=TRUE}
finalPred <- predict(modFitRF, testing)

prediction_results <- data.frame(prediction = finalPred)

print(prediction_results)
```
